{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "495d309a",
   "metadata": {},
   "source": [
    "# NovaCred Credit Application — Governance Assessment\n",
    "\n",
    "**Role:** Governance Officer  \n",
    "\n",
    "> This notebook covers the governance layer of the NovaCred audit: PII identification, GDPR compliance mapping, EU AI Act classification, pseudonymization demonstration, and actionable governance recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72cb9f4",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Setup & Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f603efd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import hashlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client[\"novacred\"]\n",
    "collection = db[\"credit_applications\"]\n",
    "\n",
    "# Load JSON \n",
    "data_path = Path('../data/raw_credit_applications.json')\n",
    "with open(data_path, 'r') as f:\n",
    "    raw_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12df7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection already populated — skipping insert.\n",
      "Total records in collection: 502\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('69a1a95b3a6b5d003e46fb20'),\n",
       " 'applicant_info': {'full_name': 'Jerry Smith',\n",
       "  'email': 'jerry.smith17@hotmail.com',\n",
       "  'ssn': '596-64-4340',\n",
       "  'ip_address': '192.168.48.155',\n",
       "  'gender': 'Male',\n",
       "  'date_of_birth': '2001-03-09',\n",
       "  'zip_code': '10036'},\n",
       " 'financials': {'annual_income': 73000,\n",
       "  'credit_history_months': 23,\n",
       "  'debt_to_income': 0.2,\n",
       "  'savings_balance': 31212},\n",
       " 'spending_behavior': [{'category': 'Shopping', 'amount': 480},\n",
       "  {'category': 'Rent', 'amount': 790},\n",
       "  {'category': 'Alcohol', 'amount': 247}],\n",
       " 'decision': {'loan_approved': False,\n",
       "  'rejection_reason': 'algorithm_risk_score'},\n",
       " 'processing_timestamp': '2024-01-15T00:00:00Z',\n",
       " 'old_id': 'app_200'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change ID name \n",
    "for doc in raw_data:\n",
    "    if \"_id\" in doc:\n",
    "        doc[\"old_id\"] = doc.pop(\"_id\")\n",
    "\n",
    "\n",
    "print(f\"Total records in collection: {collection.count_documents({})}\")\n",
    "\n",
    "# Preview one document\n",
    "collection.find_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b045eb87",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. PII Identification\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d07e5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MongoDB-based PII scan — counts & percentages\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "total = collection.count_documents({})\n",
    "sample_docs = list(collection.find().limit(500))\n",
    "if not sample_docs:\n",
    "    raise RuntimeError('No documents sampled from MongoDB collection.')\n",
    "\n",
    "def flatten_keys(doc, prefix=''):\n",
    "    keys = set()\n",
    "    for k, v in doc.items():\n",
    "        path = f\"{prefix}.{k}\" if prefix else k\n",
    "        if isinstance(v, dict):\n",
    "            keys |= flatten_keys(v, path)\n",
    "        elif isinstance(v, list):\n",
    "            keys.add(path)\n",
    "            if v and isinstance(v[0], dict):\n",
    "                for subk in v[0].keys():\n",
    "                    keys.add(f\"{path}.{subk}\")\n",
    "        else:\n",
    "            keys.add(path)\n",
    "    return keys\n",
    "\n",
    "all_keys = set()\n",
    "for d in sample_docs:\n",
    "    all_keys |= flatten_keys(d)\n",
    "all_keys = sorted(all_keys)\n",
    "\n",
    "stats = []\n",
    "for field in all_keys:\n",
    "    try:\n",
    "        exists = collection.count_documents({field: {'$exists': True}})\n",
    "    except Exception:\n",
    "        exists = 0\n",
    "    stats.append(dict(field=field, exists=exists))\n",
    "\n",
    "# ── Print table ──────────────────────────────────────────────────────────────\n",
    "print(f\"Total records in collection: {total}\\n\")\n",
    "header = f\"{'Field':<45} {'Present':>14}\"\n",
    "print(header)\n",
    "print('─' * len(header))\n",
    "\n",
    "for s in sorted(stats, key=lambda x: x['field']):\n",
    "    if s['exists'] > 0:\n",
    "        n = s['exists']\n",
    "        print(f\"{s['field'][:45]:<45} {n:>5} ({n/total*100:5.1f}%)\")\n",
    "\n",
    "# ── PII summary ───────────────────────────────────────────────────────────────\n",
    "print(\"\\n── PII Field Coverage Summary ──────────────────────────────────────────\")\n",
    "email_pat = r'^[\\w\\.\\-\\+]+@[\\w\\.\\-]+\\.[a-zA-Z]{2,}$'\n",
    "ssn_pat   = r'^\\d{3}-\\d{2}-\\d{4}$'\n",
    "ip_pat    = r'^\\d{1,3}(?:\\.\\d{1,3}){3}$'\n",
    "date_pat  = r'^\\d{4}-\\d{2}-\\d{2}$|^\\d{2}/\\d{2}/\\d{4}$|^\\d{2}/\\d{2}/\\d{2,4}$'\n",
    "zip_pat   = r'^\\d{3,5}$'\n",
    "\n",
    "pii_fields = {\n",
    "    'full_name  (direct id)': ('applicant_info.full_name',      None),\n",
    "    'email      (direct id)': ('applicant_info.email',          email_pat),\n",
    "    'SSN        (direct id)': ('applicant_info.ssn',            ssn_pat),\n",
    "    'ip_address (direct id)': ('applicant_info.ip_address',     ip_pat),\n",
    "    'date_of_birth (quasi)':  ('applicant_info.date_of_birth',  date_pat),\n",
    "    'zip_code   (quasi)':     ('applicant_info.zip_code',       zip_pat),\n",
    "    'gender     (quasi)':     ('applicant_info.gender',         None),\n",
    "}\n",
    "\n",
    "for label, (field, pat) in pii_fields.items():\n",
    "    if pat:\n",
    "        n = collection.count_documents({field: {'$regex': pat, '$options': 'i'}})\n",
    "    else:\n",
    "        n = collection.count_documents({field: {'$exists': True, '$ne': None, '$ne': ''}})\n",
    "    bar = '█' * int(n / total * 40)\n",
    "    print(f\"  {label:<30} {n:>4}/{total}  ({n/total*100:5.1f}%)  {bar}\")\n",
    "\n",
    "# ── Sensitive spending categories ────────────────────────────────────────────\n",
    "print(\"\\n── Sensitive Spending Categories (Article 9 risk) ──────────────────────\")\n",
    "sensitive_cats = {'Healthcare', 'Gambling', 'Adult Entertainment', 'Alcohol'}\n",
    "cat_counts = Counter()\n",
    "records_with_sensitive = set()\n",
    "for doc in collection.find({}, {'spending_behavior': 1}):\n",
    "    sb = doc.get('spending_behavior', [])\n",
    "    if isinstance(sb, list):\n",
    "        for it in sb:\n",
    "            if isinstance(it, dict):\n",
    "                cat = it.get('category', '')\n",
    "                cat_counts[cat] += 1\n",
    "                if cat in sensitive_cats:\n",
    "                    records_with_sensitive.add(str(doc['_id']))\n",
    "\n",
    "print(f\"  Records containing at least one sensitive category: \"\n",
    "      f\"{len(records_with_sensitive)}/{total} ({len(records_with_sensitive)/total*100:.1f}%)\\n\")\n",
    "for cat in sorted(sensitive_cats):\n",
    "    n = cat_counts[cat]\n",
    "    bar = '█' * int(n / total * 40)\n",
    "    print(f\"  {cat:<25} {n:>4} entries  {bar}\")\n",
    "\n",
    "print(\"\\n  All spending categories (entry count):\")\n",
    "for cat, cnt in cat_counts.most_common():\n",
    "    print(f\"    {cat:<25} {cnt:>4}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e75678",
   "metadata": {},
   "source": [
    "### PII Inventory (based on GDPR Article 4(1))\n",
    "- **Direct identifiers (High risk)**: `applicant_info.full_name`, `applicant_info.email`, `applicant_info.ssn`, `applicant_info.ip_address`, original `_id` (application id).  \n",
    "\n",
    "\n",
    "- **Quasi-identifiers (Moderate risk)**: `applicant_info.date_of_birth`, `applicant_info.zip_code`, `applicant_info.gender`, `spending_behavior` categories (when granular).  \n",
    "\n",
    "\n",
    "- **Financial & decision attributes (Personal; contextually sensitive)**: `financials.annual_income`, `financials.credit_history_months`, `financials.debt_to_income`, `financials.savings_balance`, `decision.loan_approved`, `decision.interest_rate`, `decision.approved_amount`, `loan_purpose`, `processing_timestamp`.  \n",
    "\n",
    "\n",
    "- **Potential Article 9 risks (Requires DPIA / higher protection)**: spending categories such as `Healthcare`, `Gambling`, `Adult Entertainment` can enable sensitive inferences (health, addictions, sexual behaviour).  \n",
    "  - Risk: inferred special-category data — treat as sensitive.  \n",
    "\n",
    "- **System / metadata**: `processing_timestamp`, database ObjectId (if kept), ingestion logs — personal when linked to an individual.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xcj7ti2xx5",
   "metadata": {},
   "source": [
    "### Why This Dataset Is Unsafe in a Data Breach (GDPR Perspective)\n",
    "\n",
    "All 502 records store direct identifiers (name, SSN, email), financial data, and sensitive spending categories **in plaintext in a single document**. A single compromised credential exposes everything at once — with no encryption, hashing, or separation to limit the damage. This triggers mandatory supervisory authority notification within 72 hours (Art. 33) and direct notification to all affected individuals (Art. 34), with potential fines up to €10M under Art. 83(4)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pdtjx0rbarm",
   "source": "---\n## 3. GDPR Compliance Mapping",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "c5g0j4odckv",
   "source": "### Lawful Basis — Art. 6 & Art. 22\n\nCredit application processing relies on **Art. 6(1)(b)** — necessary for the performance of a contract. SSN collection requires the stronger basis of **Art. 6(1)(c)** (legal obligation) and must be strictly limited to identity verification.\n\nAutomated rejections (e.g., `algorithm_risk_score`) trigger **Art. 22**: applicants have the right to request human review of any solely automated decision with significant legal effect.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "c00k1jk9ius",
   "source": "### Data Minimization — Art. 5(1)(c)\n\nSeveral fields exceed what is strictly necessary for credit assessment:\n\n- **`ip_address`** — irrelevant to creditworthiness; should not be retained after submission.\n- **`spending_behavior` categories** — granular categories (`Healthcare`, `Gambling`, `Adult Entertainment`) enable sensitive inferences beyond what scoring requires; aggregated totals suffice.\n- **`ssn`** — needed only for identity verification at intake; must not persist in the operational collection afterwards.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "tp8vd08m649",
   "source": "### Storage Limitation — Art. 5(1)(e)\n\nNo retention schedule exists in the current system. Recommended policy:\n\n- **Rejected applications** — retain for the statutory minimum (typically 5 years under EU financial regulation), then delete or fully anonymize.\n- **Approved loans** — retain for the loan term plus the regulatory minimum.\n- **`ip_address`** — delete immediately after the application session closes.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "thficcu7kpr",
   "source": "### Right to Erasure — Art. 17\n\nThe pseudonymisation design supports erasure requests: deleting a subject's record from `identity_store` severs the name-to-token link, rendering the main collection entry effectively anonymous.\n\nTwo limitations apply:\n1. Backup copies and audit logs must be purged separately within the response window.\n2. Erasure may be refused where retention is required by law (e.g., anti-money laundering obligations).",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "6m6lhtpaq19",
   "source": "---\n## 4. EU AI Act Classification",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "zh6ggqvjffi",
   "source": "### Risk Classification — Annex III, Point 5(b)\n\nNovaCred's credit scoring algorithm is explicitly classified as **high-risk** under the EU AI Act (Annex III, §5(b)): *\"AI systems intended to be used to evaluate the creditworthiness of natural persons or establish their credit score.\"*\n\nThe determining factor is the **use case**, not model complexity — any automated system producing credit decisions with significant legal effect on individuals falls under this classification, regardless of the underlying algorithm.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "r4fyrxjqnw",
   "source": "### High-Risk Obligations — Title III, Chapter 2\n\nAs a deployer of a high-risk AI system, NovaCred must comply with:\n\n- **Art. 9 — Risk management**: Continuous identification and mitigation of risks throughout the system lifecycle.\n- **Art. 10 — Data governance**: Training data must be examined for biases; the presence of `gender` as an input feature requires particular scrutiny under this article.\n- **Art. 12 — Logging**: Automatic logging of system operation to ensure traceability of decisions — absent in the current dataset (`rejection_reason` alone is insufficient).\n- **Art. 14 — Human oversight**: Measures enabling human intervention or override must be in place; `algorithm_risk_score` rejections with no visible human review mechanism raise a direct compliance gap.\n- **Art. 26 — Deployer obligations**: NovaCred must monitor system operation, report serious incidents to the national authority, and retain logs for at least 6 months.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "6ftd8wgap38",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Pseudonymisation — Full Name\n",
    "\n",
    "Replace `applicant_info.full_name` with a random token and store the mapping in a separate `identity_store` collection. The main `credit_applications` collection no longer contains real names; only the identity store — which should be access-controlled separately — can resolve a token back to a person."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dvyi3kk29mm",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "identity_store = db[\"identity_store\"]\n",
    "\n",
    "# Only run if not already pseudonymised\n",
    "if identity_store.count_documents({}) == 0:\n",
    "    for doc in collection.find({}, {\"_id\": 1, \"applicant_info.full_name\": 1}):\n",
    "        full_name = doc.get(\"applicant_info\", {}).get(\"full_name\")\n",
    "        if not full_name:\n",
    "            continue\n",
    "\n",
    "        token = str(uuid.uuid4())\n",
    "\n",
    "        # Store mapping in identity_store\n",
    "        identity_store.insert_one({\n",
    "            \"token\": token,\n",
    "            \"full_name\": full_name,\n",
    "            \"application_id\": doc[\"_id\"]\n",
    "        })\n",
    "\n",
    "        # Replace name with token in main collection\n",
    "        collection.update_one(\n",
    "            {\"_id\": doc[\"_id\"]},\n",
    "            {\"$set\": {\"applicant_info.full_name\": token}}\n",
    "        )\n",
    "\n",
    "    print(f\"Pseudonymised {identity_store.count_documents({})} records.\")\n",
    "else:\n",
    "    print(\"Already pseudonymised — skipping.\")\n",
    "\n",
    "# Preview: main collection no longer holds real names\n",
    "print(\"\\n── Main collection (no real name) ──\")\n",
    "doc = collection.find_one({}, {\"applicant_info.full_name\": 1, \"_id\": 0})\n",
    "print(doc)\n",
    "\n",
    "# Preview: identity store holds the mapping\n",
    "print(\"\\n── Identity store (restricted access) ──\")\n",
    "identity_store.find_one({}, {\"_id\": 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hx9rczmz16g",
   "metadata": {},
   "source": [
    " Each applicant's real name is replaced with a random UUID token in the main database. The mapping between token and real name lives in a separate `identity_store` collection that would, in a real system, have stricter access controls. The original JSON file on disk is not modified. This is pseudonymisation — not anonymisation — because the name can still be recovered if you have access to the identity store."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fy30tv0qw2g",
   "source": "---\n## 6. GDPR Data Subject Rights\n\nThe five core rights applicable to NovaCred's processing. Rights to erasure and automated decision-making (Art. 17 & Art. 22) were introduced in Sections 3 and 4 respectively — this section provides the full picture with example queries.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "b8jrxllbb4",
   "source": "### Right of Access — Art. 15\n\nApplicants may request all data NovaCred holds on them. The lookup uses `identity_store` to resolve the subject's name to their token, then retrieves the full record from the main collection.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "6onmlckqjmt",
   "source": "# Art. 15 — Right of Access\n# Resolve name → token via identity_store, then retrieve the full record\n\nsubject = identity_store.find_one({}, {\"token\": 1, \"full_name\": 1, \"_id\": 0})\ntoken = subject[\"token\"]\nprint(f\"Subject: {subject['full_name']}  →  token: {token[:8]}...\")\n\nsubject_data = collection.find_one({\"applicant_info.full_name\": token}, {\"_id\": 0})\nsubject_data",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "zq5kjlltns",
   "source": "### Right to Rectification — Art. 16\n\nApplicants may request correction of inaccurate personal data. The update targets the main collection via the applicant's token — the identity store is not modified since the name itself has not changed.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "if744v7l80e",
   "source": "# Art. 16 — Right to Rectification\n# Correct an inaccurate field — example: wrong date of birth\n\nresult = collection.update_one(\n    {\"applicant_info.full_name\": token},\n    {\"$set\": {\"applicant_info.date_of_birth\": \"1990-05-15\"}}\n)\nprint(f\"Matched: {result.matched_count}  Modified: {result.modified_count}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "fsa9ptbrlyf",
   "source": "### Right to Erasure — Art. 17\n\nSee Section 3 for full discussion. Erasure is executed in two steps: delete the `identity_store` mapping (severing the name-to-token link), then delete the application record from the main collection.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "6anpunuvh16",
   "source": "# Art. 17 — Right to Erasure\n# Step 1: delete from identity_store — severs the name-to-token link\n# Step 2: delete the application record from the main collection\n# (Commented out to avoid modifying live data in this demo — see Section 3 for design rationale)\n\n# identity_store.delete_one({\"token\": token})\n# collection.delete_one({\"applicant_info.full_name\": token})\n\nprint(\"Erasure procedure: remove token mapping from identity_store, then delete record from main collection.\")\nprint(\"Once executed, no link between the token and the real identity remains.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "khtzs6agzh",
   "source": "### Right to Data Portability — Art. 20\n\nApplicants may request their data in a structured, machine-readable format for transfer to another provider. The export must cover all fields provided by the subject — financials, spending behaviour, and decision outputs.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "81n3x00tllr",
   "source": "# Art. 20 — Right to Data Portability\n# Export the subject's full record as a portable JSON object\n\nsubject_data = collection.find_one({\"applicant_info.full_name\": token}, {\"_id\": 0})\nportable_export = json.dumps(subject_data, default=str, indent=2)\nprint(portable_export)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "dcphtg71wqa",
   "source": "### Right to Object — Art. 21\n\nApplicants may object to processing for profiling purposes. On receipt of an objection, NovaCred must stop automated processing of that record, log the objection with a timestamp, and route it to human review.\n\nThis is a workflow obligation — a production system would set a status flag (e.g., `processing_status: \"objection_pending\"`) and create an audit trail entry. No single query implements it.",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}